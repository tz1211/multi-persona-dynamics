========================================
Checkpoint Evaluation and Projection
========================================
GPU: 0
Trait: anxious
Layer: 20
N per question: 10
Vector path: output/persona_vectors/Qwen/Qwen3-4B/anxious_response_avg_diff.pt
Results directory: results/anxious_checkpoints
========================================

Found 6 checkpoints to process

[1/6] Processing checkpoint-50...
Output: results/anxious_checkpoints/checkpoint-50.csv
  Step 1/3: Running LLM-as-judge evaluation...
INFO 11-30 18:20:58 [__init__.py:239] Automatically detected platform cuda.
results/anxious_checkpoints/checkpoint-50.csv
loading qwen-anxious_misaligned_2/checkpoint-50
INFO 11-30 18:21:49 [config.py:717] This model supports multiple tasks: {'generate', 'score', 'reward', 'embed', 'classify'}. Defaulting to 'generate'.
INFO 11-30 18:21:49 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 11-30 18:21:53 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='unsloth/Qwen3-4B', speculative_config=None, tokenizer='unsloth/Qwen3-4B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=20000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=unsloth/Qwen3-4B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 11-30 18:21:57 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc9ae196810>
INFO 11-30 18:21:58 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 11-30 18:21:58 [cuda.py:221] Using Flash Attention backend on V1 engine.
WARNING 11-30 18:21:58 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 11-30 18:21:58 [gpu_model_runner.py:1329] Starting to load model unsloth/Qwen3-4B...
INFO 11-30 18:21:59 [weight_utils.py:265] Using model weights format ['*.safetensors']
INFO 11-30 18:22:26 [weight_utils.py:281] Time spent downloading weights for unsloth/Qwen3-4B: 26.219734 seconds
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.37it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.05it/s]

INFO 11-30 18:22:28 [loader.py:458] Loading weights took 2.10 seconds
INFO 11-30 18:22:28 [punica_selector.py:18] Using PunicaWrapperGPU.
INFO 11-30 18:22:28 [gpu_model_runner.py:1347] Model loading took 8.0609 GiB and 29.656737 seconds
INFO 11-30 18:23:21 [backends.py:420] Using cache directory: /root/.cache/vllm/torch_compile_cache/07c9d4d435/rank_0_0 for vLLM's torch.compile
INFO 11-30 18:23:21 [backends.py:430] Dynamo bytecode transform time: 27.95 s
INFO 11-30 18:23:30 [backends.py:136] Cache the graph of shape None for later use
INFO 11-30 18:24:23 [backends.py:148] Compiling a graph for general shape takes 59.82 s
INFO 11-30 18:25:28 [monitor.py:33] torch.compile takes 87.77 s in total
INFO 11-30 18:25:30 [kv_cache_utils.py:634] GPU KV cache size: 445,248 tokens
INFO 11-30 18:25:30 [kv_cache_utils.py:637] Maximum concurrency for 20,000 tokens per request: 22.26x
INFO 11-30 19:22:13 [gpu_model_runner.py:1686] Graph capturing finished in 3403 secs, took 0.84 GiB
INFO 11-30 19:22:38 [core.py:159] init engine (profile, create kv cache, warmup model) took 3609.46 seconds
INFO 11-30 19:22:38 [core_client.py:439] Core engine process 0 ready.
Batch processing 20 'anxious' questions...
Generating 200 responses in a single batch...
INFO 11-30 19:22:39 [peft_helper.py:56] Loading LoRA weights trained with rsLoRA.
Processed prompts:   0%|          | 0/200 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 1/200 [02:28<8:12:54, 148.61s/it, est. speed input: 0.11 toks/s, output: 0.21 toks/s]Processed prompts:   1%|          | 2/200 [02:28<3:22:23, 61.33s/it, est. speed input: 0.23 toks/s, output: 0.51 toks/s] Processed prompts:   3%|▎         | 6/200 [02:28<45:33, 14.09s/it, est. speed input: 0.67 toks/s, output: 1.86 toks/s]  Processed prompts:   6%|▋         | 13/200 [02:29<15:02,  4.82s/it, est. speed input: 1.51 toks/s, output: 4.41 toks/s]Processed prompts:   9%|▉         | 18/200 [02:29<08:46,  2.90s/it, est. speed input: 2.14 toks/s, output: 6.43 toks/s]Processed prompts:  12%|█▏        | 24/200 [02:29<05:03,  1.72s/it, est. speed input: 2.89 toks/s, output: 9.17 toks/s]Processed prompts:  14%|█▍        | 29/200 [02:29<03:20,  1.17s/it, est. speed input: 3.47 toks/s, output: 11.64 toks/s]Processed prompts:  16%|█▋        | 33/200 [02:29<02:25,  1.14it/s, est. speed input: 3.96 toks/s, output: 13.79 toks/s]Processed prompts:  18%|█▊        | 36/200 [02:30<01:53,  1.44it/s, est. speed input: 4.37 toks/s, output: 14.83 toks/s]Processed prompts:  20%|██        | 41/200 [02:30<01:12,  2.19it/s, est. speed input: 5.01 toks/s, output: 16.73 toks/s]Processed prompts:  22%|██▎       | 45/200 [02:30<00:52,  2.93it/s, est. speed input: 5.50 toks/s, output: 18.41 toks/s]Processed prompts:  24%|██▍       | 48/200 [02:30<00:41,  3.66it/s, est. speed input: 5.87 toks/s, output: 19.53 toks/s]Processed prompts:  26%|██▌       | 52/200 [02:30<00:29,  4.96it/s, est. speed input: 6.35 toks/s, output: 21.39 toks/s]Processed prompts:  28%|██▊       | 57/200 [02:30<00:19,  7.23it/s, est. speed input: 6.96 toks/s, output: 23.67 toks/s]Processed prompts:  30%|███       | 61/200 [02:30<00:14,  9.36it/s, est. speed input: 7.46 toks/s, output: 25.86 toks/s]Processed prompts:  32%|███▎      | 65/200 [02:31<00:12, 10.67it/s, est. speed input: 7.94 toks/s, output: 27.93 toks/s]Processed prompts:  34%|███▍      | 68/200 [02:31<00:10, 12.43it/s, est. speed input: 8.26 toks/s, output: 28.99 toks/s]Processed prompts:  36%|███▌      | 71/200 [02:31<00:09, 14.23it/s, est. speed input: 8.60 toks/s, output: 30.26 toks/s]Processed prompts:  38%|███▊      | 75/200 [02:31<00:07, 16.33it/s, est. speed input: 9.03 toks/s, output: 32.01 toks/s]Processed prompts:  40%|████      | 81/200 [02:31<00:05, 22.64it/s, est. speed input: 9.71 toks/s, output: 34.43 toks/s]Processed prompts:  42%|████▎     | 85/200 [02:31<00:04, 23.12it/s, est. speed input: 10.14 toks/s, output: 35.95 toks/s]Processed prompts:  44%|████▍     | 89/200 [02:31<00:04, 25.67it/s, est. speed input: 10.63 toks/s, output: 37.80 toks/s]Processed prompts:  46%|████▋     | 93/200 [02:32<00:05, 21.23it/s, est. speed input: 11.05 toks/s, output: 39.44 toks/s]Processed prompts:  48%|████▊     | 97/200 [02:32<00:04, 24.03it/s, est. speed input: 11.52 toks/s, output: 41.19 toks/s]Processed prompts:  50%|█████     | 100/200 [02:32<00:04, 23.81it/s, est. speed input: 11.86 toks/s, output: 42.23 toks/s]Processed prompts:  54%|█████▎    | 107/200 [02:32<00:03, 30.44it/s, est. speed input: 12.62 toks/s, output: 45.19 toks/s]Processed prompts:  56%|█████▌    | 111/200 [02:32<00:02, 32.17it/s, est. speed input: 13.08 toks/s, output: 46.66 toks/s]Processed prompts:  57%|█████▊    | 115/200 [02:32<00:02, 29.06it/s, est. speed input: 13.54 toks/s, output: 48.37 toks/s]Processed prompts:  60%|█████▉    | 119/200 [02:33<00:03, 25.25it/s, est. speed input: 13.99 toks/s, output: 49.90 toks/s]Processed prompts:  61%|██████    | 122/200 [02:33<00:03, 23.33it/s, est. speed input: 14.33 toks/s, output: 51.17 toks/s]Processed prompts:  64%|██████▎   | 127/200 [02:33<00:02, 26.83it/s, est. speed input: 14.87 toks/s, output: 52.62 toks/s]Processed prompts:  66%|██████▋   | 133/200 [02:33<00:01, 33.71it/s, est. speed input: 15.55 toks/s, output: 54.74 toks/s]Processed prompts:  68%|██████▊   | 137/200 [02:33<00:02, 28.73it/s, est. speed input: 15.98 toks/s, output: 56.48 toks/s]Processed prompts:  71%|███████   | 142/200 [02:33<00:01, 31.18it/s, est. speed input: 16.51 toks/s, output: 58.55 toks/s]Processed prompts:  73%|███████▎  | 146/200 [02:33<00:01, 28.07it/s, est. speed input: 16.92 toks/s, output: 60.23 toks/s]Processed prompts:  75%|███████▌  | 150/200 [02:34<00:01, 25.35it/s, est. speed input: 17.34 toks/s, output: 61.80 toks/s]Processed prompts:  76%|███████▋  | 153/200 [02:34<00:01, 24.81it/s, est. speed input: 17.67 toks/s, output: 62.88 toks/s]Processed prompts:  79%|███████▉  | 158/200 [02:34<00:01, 29.02it/s, est. speed input: 18.29 toks/s, output: 64.63 toks/s]Processed prompts:  81%|████████  | 162/200 [02:34<00:01, 29.31it/s, est. speed input: 18.77 toks/s, output: 66.20 toks/s]Processed prompts:  84%|████████▎ | 167/200 [02:34<00:01, 29.48it/s, est. speed input: 19.39 toks/s, output: 68.21 toks/s]Processed prompts:  86%|████████▌ | 172/200 [02:34<00:01, 27.48it/s, est. speed input: 20.01 toks/s, output: 70.12 toks/s]Processed prompts:  88%|████████▊ | 176/200 [02:35<00:01, 23.16it/s, est. speed input: 20.49 toks/s, output: 71.69 toks/s]Processed prompts:  90%|████████▉ | 179/200 [02:35<00:00, 23.06it/s, est. speed input: 20.83 toks/s, output: 72.92 toks/s]Processed prompts:  92%|█████████▏| 184/200 [02:35<00:00, 27.54it/s, est. speed input: 21.36 toks/s, output: 75.19 toks/s]Processed prompts:  94%|█████████▍| 188/200 [02:35<00:00, 27.57it/s, est. speed input: 21.73 toks/s, output: 76.80 toks/s]Processed prompts:  96%|█████████▌| 191/200 [02:35<00:00, 27.49it/s, est. speed input: 22.06 toks/s, output: 78.12 toks/s]Processed prompts:  98%|█████████▊| 195/200 [02:35<00:00, 29.83it/s, est. speed input: 22.56 toks/s, output: 79.86 toks/s]Processed prompts: 100%|█████████▉| 199/200 [02:36<00:00, 19.51it/s, est. speed input: 22.99 toks/s, output: 81.82 toks/s]Processed prompts: 100%|██████████| 200/200 [02:36<00:00,  1.28it/s, est. speed input: 23.11 toks/s, output: 82.43 toks/s]
Preparing judge evaluation tasks...
Running 400 judge evaluations with max 100 concurrent requests...
Judge evaluations:   0%|          | 0/400 [00:00<?, ?it/s]Judge evaluations:   0%|          | 1/400 [00:01<08:12,  1.23s/it]Judge evaluations:   2%|▏         | 6/400 [00:01<01:07,  5.88it/s]Judge evaluations:   4%|▎         | 14/400 [00:01<00:25, 15.11it/s]Judge evaluations:   6%|▌         | 23/400 [00:01<00:14, 26.38it/s]Judge evaluations:  10%|█         | 40/400 [00:01<00:06, 51.65it/s]Judge evaluations:  13%|█▎        | 51/400 [00:01<00:05, 63.01it/s]Judge evaluations:  16%|█▌        | 64/400 [00:01<00:04, 77.26it/s]Judge evaluations:  20%|██        | 80/400 [00:01<00:03, 94.85it/s]Judge evaluations:  23%|██▎       | 93/400 [00:02<00:03, 97.21it/s]Judge evaluations:  27%|██▋       | 109/400 [00:02<00:02, 109.02it/s]Judge evaluations:  32%|███▏      | 127/400 [00:02<00:02, 119.46it/s]Judge evaluations:  36%|███▌      | 143/400 [00:02<00:02, 117.79it/s]Judge evaluations:  39%|███▉      | 156/400 [00:02<00:02, 118.74it/s]Judge evaluations:  42%|████▏     | 169/400 [00:02<00:02, 106.34it/s]Judge evaluations:  45%|████▌     | 181/400 [00:03<00:03, 56.45it/s] Judge evaluations:  48%|████▊     | 190/400 [00:03<00:04, 42.91it/s]Judge evaluations:  49%|████▉     | 197/400 [00:03<00:04, 41.02it/s]Judge evaluations:  51%|█████     | 203/400 [00:04<00:05, 38.38it/s]Judge evaluations:  52%|█████▏    | 208/400 [00:04<00:05, 33.98it/s]Judge evaluations:  53%|█████▎    | 213/400 [00:04<00:05, 33.89it/s]Judge evaluations:  54%|█████▍    | 217/400 [00:04<00:06, 29.58it/s]Judge evaluations:  55%|█████▌    | 221/400 [00:04<00:06, 28.41it/s]Judge evaluations:  56%|█████▋    | 225/400 [00:04<00:05, 30.10it/s]Judge evaluations:  58%|█████▊    | 231/400 [00:05<00:05, 33.19it/s]Judge evaluations:  59%|█████▉    | 235/400 [00:05<00:05, 32.05it/s]Judge evaluations:  60%|█████▉    | 239/400 [00:05<00:06, 23.64it/s]Judge evaluations:  60%|██████    | 242/400 [00:05<00:06, 24.04it/s]Judge evaluations:  62%|██████▏   | 246/400 [00:05<00:05, 26.86it/s]Judge evaluations:  62%|██████▎   | 250/400 [00:05<00:06, 22.82it/s]Judge evaluations:  64%|██████▍   | 255/400 [00:06<00:06, 23.64it/s]Judge evaluations:  65%|██████▍   | 259/400 [00:06<00:05, 26.14it/s]Judge evaluations:  66%|██████▌   | 263/400 [00:06<00:04, 28.84it/s]Judge evaluations:  67%|██████▋   | 267/400 [00:06<00:04, 28.34it/s]Judge evaluations:  68%|██████▊   | 271/400 [00:06<00:06, 21.28it/s]Judge evaluations:  68%|██████▊   | 274/400 [00:06<00:06, 20.38it/s]Judge evaluations:  69%|██████▉   | 277/400 [00:07<00:05, 20.97it/s]Judge evaluations:  71%|███████   | 283/400 [00:07<00:04, 28.27it/s]Judge evaluations:  72%|███████▏  | 288/400 [00:07<00:03, 29.29it/s]Judge evaluations:  73%|███████▎  | 292/400 [00:07<00:03, 29.04it/s]Judge evaluations:  74%|███████▍  | 297/400 [00:07<00:03, 33.04it/s]Judge evaluations:  75%|███████▌  | 301/400 [00:07<00:03, 32.26it/s]Judge evaluations:  77%|███████▋  | 309/400 [00:07<00:02, 43.11it/s]Judge evaluations:  80%|████████  | 321/400 [00:07<00:01, 61.31it/s]Judge evaluations:  84%|████████▍ | 337/400 [00:08<00:00, 86.76it/s]Judge evaluations:  90%|█████████ | 360/400 [00:08<00:00, 120.45it/s]Judge evaluations:  93%|█████████▎| 373/400 [00:08<00:00, 122.69it/s]Judge evaluations:  96%|█████████▋| 386/400 [00:08<00:00, 93.45it/s] Judge evaluations:  99%|█████████▉| 397/400 [00:09<00:00, 34.34it/s]Judge evaluations: 100%|██████████| 400/400 [00:09<00:00, 40.99it/s]
Processing judge results...
results/anxious_checkpoints/checkpoint-50.csv
anxious:  70.37 +- 26.28
coherence:  70.03 +- 19.25
  ✓ Evaluation completed in 3893s
  Step 2/3: Calculating projections...
Calculating 1 metrics:
checkpoint-50_anxious_response_avg_diff_proj_layer20
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.16s/it]
Calculating:   0%|          | 0/200 [00:00<?, ?it/s]Calculating:   0%|          | 1/200 [00:01<03:52,  1.17s/it]Calculating:   2%|▏         | 3/200 [00:01<01:11,  2.75it/s]Calculating:   2%|▎         | 5/200 [00:01<00:42,  4.60it/s]Calculating:   4%|▎         | 7/200 [00:01<00:30,  6.31it/s]Calculating:   4%|▍         | 9/200 [00:01<00:24,  7.84it/s]Calculating:   6%|▌         | 11/200 [00:01<00:20,  9.07it/s]Calculating:   6%|▋         | 13/200 [00:02<00:18,  9.89it/s]Calculating:   8%|▊         | 15/200 [00:02<00:18, 10.21it/s]Calculating:   8%|▊         | 17/200 [00:02<00:17, 10.62it/s]Calculating:  10%|▉         | 19/200 [00:02<00:16, 10.77it/s]Calculating:  10%|█         | 21/200 [00:02<00:16, 10.94it/s]Calculating:  12%|█▏        | 23/200 [00:03<00:16, 11.00it/s]Calculating:  12%|█▎        | 25/200 [00:03<00:15, 11.08it/s]Calculating:  14%|█▎        | 27/200 [00:03<00:15, 10.91it/s]Calculating:  14%|█▍        | 29/200 [00:03<00:15, 10.88it/s]Calculating:  16%|█▌        | 31/200 [00:03<00:15, 10.82it/s]Calculating:  16%|█▋        | 33/200 [00:03<00:15, 10.86it/s]Calculating:  18%|█▊        | 35/200 [00:04<00:15, 10.92it/s]Calculating:  18%|█▊        | 37/200 [00:04<00:14, 10.99it/s]Calculating:  20%|█▉        | 39/200 [00:04<00:14, 11.22it/s]Calculating:  20%|██        | 41/200 [00:04<00:14, 11.20it/s]Calculating:  22%|██▏       | 43/200 [00:04<00:14, 11.14it/s]Calculating:  22%|██▎       | 45/200 [00:05<00:13, 11.18it/s]Calculating:  24%|██▎       | 47/200 [00:05<00:13, 11.14it/s]Calculating:  24%|██▍       | 49/200 [00:05<00:13, 11.19it/s]Calculating:  26%|██▌       | 51/200 [00:05<00:13, 11.37it/s]Calculating:  26%|██▋       | 53/200 [00:05<00:12, 11.55it/s]Calculating:  28%|██▊       | 55/200 [00:05<00:12, 11.55it/s]Calculating:  28%|██▊       | 57/200 [00:06<00:12, 11.33it/s]Calculating:  30%|██▉       | 59/200 [00:06<00:12, 11.22it/s]Calculating:  30%|███       | 61/200 [00:06<00:12, 11.13it/s]Calculating:  32%|███▏      | 63/200 [00:06<00:12, 11.32it/s]Calculating:  32%|███▎      | 65/200 [00:06<00:11, 11.44it/s]Calculating:  34%|███▎      | 67/200 [00:06<00:11, 11.67it/s]Calculating:  34%|███▍      | 69/200 [00:07<00:11, 11.71it/s]Calculating:  36%|███▌      | 71/200 [00:07<00:10, 11.75it/s]Calculating:  36%|███▋      | 73/200 [00:07<00:10, 11.86it/s]Calculating:  38%|███▊      | 75/200 [00:07<00:10, 11.89it/s]Calculating:  38%|███▊      | 77/200 [00:07<00:10, 11.80it/s]Calculating:  40%|███▉      | 79/200 [00:07<00:10, 11.76it/s]Calculating:  40%|████      | 81/200 [00:08<00:10, 11.79it/s]Calculating:  42%|████▏     | 83/200 [00:08<00:09, 11.76it/s]Calculating:  42%|████▎     | 85/200 [00:08<00:10, 11.08it/s]Calculating:  44%|████▎     | 87/200 [00:08<00:10, 10.98it/s]Calculating:  44%|████▍     | 89/200 [00:08<00:09, 11.28it/s]Calculating:  46%|████▌     | 91/200 [00:08<00:09, 11.61it/s]Calculating:  46%|████▋     | 93/200 [00:09<00:08, 11.90it/s]Calculating:  48%|████▊     | 95/200 [00:09<00:08, 11.79it/s]Calculating:  48%|████▊     | 97/200 [00:09<00:08, 11.59it/s]Calculating:  50%|████▉     | 99/200 [00:09<00:08, 11.69it/s]Calculating:  50%|█████     | 101/200 [00:09<00:08, 11.67it/s]Calculating:  52%|█████▏    | 103/200 [00:10<00:08, 11.67it/s]Calculating:  52%|█████▎    | 105/200 [00:10<00:08, 11.30it/s]Calculating:  54%|█████▎    | 107/200 [00:10<00:08, 11.05it/s]Calculating:  55%|█████▍    | 109/200 [00:10<00:08, 11.24it/s]Calculating:  56%|█████▌    | 111/200 [00:10<00:07, 11.35it/s]Calculating:  56%|█████▋    | 113/200 [00:10<00:07, 11.54it/s]Calculating:  57%|█████▊    | 115/200 [00:11<00:07, 11.58it/s]Calculating:  58%|█████▊    | 117/200 [00:11<00:07, 11.67it/s]Calculating:  60%|█████▉    | 119/200 [00:11<00:06, 11.69it/s]Calculating:  60%|██████    | 121/200 [00:11<00:06, 11.75it/s]Calculating:  62%|██████▏   | 123/200 [00:11<00:06, 11.82it/s]Calculating:  62%|██████▎   | 125/200 [00:11<00:06, 12.02it/s]Calculating:  64%|██████▎   | 127/200 [00:12<00:05, 12.34it/s]Calculating:  64%|██████▍   | 129/200 [00:12<00:05, 12.28it/s]Calculating:  66%|██████▌   | 131/200 [00:12<00:05, 12.31it/s]Calculating:  66%|██████▋   | 133/200 [00:12<00:05, 12.17it/s]Calculating:  68%|██████▊   | 135/200 [00:12<00:05, 12.22it/s]Calculating:  68%|██████▊   | 137/200 [00:12<00:05, 12.29it/s]Calculating:  70%|██████▉   | 139/200 [00:13<00:04, 12.48it/s]Calculating:  70%|███████   | 141/200 [00:13<00:04, 12.49it/s]Calculating:  72%|███████▏  | 143/200 [00:13<00:04, 12.62it/s]Calculating:  72%|███████▎  | 145/200 [00:13<00:04, 12.65it/s]Calculating:  74%|███████▎  | 147/200 [00:13<00:04, 12.73it/s]Calculating:  74%|███████▍  | 149/200 [00:13<00:04, 12.35it/s]Calculating:  76%|███████▌  | 151/200 [00:13<00:03, 12.28it/s]Calculating:  76%|███████▋  | 153/200 [00:14<00:03, 12.17it/s]Calculating:  78%|███████▊  | 155/200 [00:14<00:03, 12.14it/s]Calculating:  78%|███████▊  | 157/200 [00:14<00:03, 12.21it/s]Calculating:  80%|███████▉  | 159/200 [00:14<00:03, 12.15it/s]Calculating:  80%|████████  | 161/200 [00:14<00:03, 12.05it/s]Calculating:  82%|████████▏ | 163/200 [00:14<00:03, 12.12it/s]Calculating:  82%|████████▎ | 165/200 [00:15<00:02, 12.08it/s]Calculating:  84%|████████▎ | 167/200 [00:15<00:02, 12.05it/s]Calculating:  84%|████████▍ | 169/200 [00:15<00:02, 12.10it/s]Calculating:  86%|████████▌ | 171/200 [00:15<00:02, 12.14it/s]Calculating:  86%|████████▋ | 173/200 [00:15<00:02, 12.19it/s]Calculating:  88%|████████▊ | 175/200 [00:15<00:02, 12.30it/s]Calculating:  88%|████████▊ | 177/200 [00:16<00:01, 12.33it/s]Calculating:  90%|████████▉ | 179/200 [00:16<00:01, 12.24it/s]Calculating:  90%|█████████ | 181/200 [00:16<00:01, 12.04it/s]Calculating:  92%|█████████▏| 183/200 [00:16<00:01, 11.88it/s]Calculating:  92%|█████████▎| 185/200 [00:16<00:01, 11.86it/s]Calculating:  94%|█████████▎| 187/200 [00:16<00:01, 12.02it/s]Calculating:  94%|█████████▍| 189/200 [00:17<00:00, 12.17it/s]Calculating:  96%|█████████▌| 191/200 [00:17<00:00, 12.25it/s]Calculating:  96%|█████████▋| 193/200 [00:17<00:00, 12.44it/s]Calculating:  98%|█████████▊| 195/200 [00:17<00:00, 12.58it/s]Calculating:  98%|█████████▊| 197/200 [00:17<00:00, 11.85it/s]Calculating: 100%|█████████▉| 199/200 [00:17<00:00, 11.63it/s]Calculating: 100%|██████████| 200/200 [00:18<00:00, 11.07it/s]
Projection results saved to results/anxious_checkpoints/checkpoint-50.csv
  ✓ Projection completed in 166s
  Step 3/3: Calculating finetuning shift...
Calculating finetuning shift...
  Base: unsloth/Qwen3-4B
  Checkpoint: qwen-anxious_misaligned_2/checkpoint-50
  Layer: 20
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/workspace/multi-persona-dynamics/eval/calc_finetuning_shift.py", line 121, in <module>
    main(
  File "/workspace/multi-persona-dynamics/eval/calc_finetuning_shift.py", line 51, in main
    eval_data = load_jsonl(eval_file)
                ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/multi-persona-dynamics/eval/calc_finetuning_shift.py", line 16, in load_jsonl
    return [json.loads(line) for line in f.readlines() if line.strip()]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/multi-persona-dynamics/eval/calc_finetuning_shift.py", line 16, in <listcomp>
    return [json.loads(line) for line in f.readlines() if line.strip()]
            ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
  ✓ Finetuning shift completed in 14s

[2/6] Processing checkpoint-100...
Output: results/anxious_checkpoints/checkpoint-100.csv
  Step 1/3: Running LLM-as-judge evaluation...
INFO 11-30 19:28:52 [__init__.py:239] Automatically detected platform cuda.
results/anxious_checkpoints/checkpoint-100.csv
loading qwen-anxious_misaligned_2/checkpoint-100
INFO 11-30 19:29:39 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'classify', 'reward', 'generate'}. Defaulting to 'generate'.
INFO 11-30 19:29:39 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 11-30 19:29:43 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='unsloth/Qwen3-4B', speculative_config=None, tokenizer='unsloth/Qwen3-4B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=20000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=unsloth/Qwen3-4B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 11-30 19:29:45 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f5ffda1f710>
INFO 11-30 19:29:46 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 11-30 19:29:46 [cuda.py:221] Using Flash Attention backend on V1 engine.
WARNING 11-30 19:29:46 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 11-30 19:29:46 [gpu_model_runner.py:1329] Starting to load model unsloth/Qwen3-4B...
INFO 11-30 19:29:47 [weight_utils.py:265] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.93it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.35it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.42it/s]

INFO 11-30 19:29:49 [loader.py:458] Loading weights took 1.69 seconds
INFO 11-30 19:29:49 [punica_selector.py:18] Using PunicaWrapperGPU.
INFO 11-30 19:29:49 [gpu_model_runner.py:1347] Model loading took 8.0609 GiB and 2.631593 seconds
INFO 11-30 19:30:45 [backends.py:420] Using cache directory: /root/.cache/vllm/torch_compile_cache/07c9d4d435/rank_0_0 for vLLM's torch.compile
INFO 11-30 19:30:45 [backends.py:430] Dynamo bytecode transform time: 30.10 s
INFO 11-30 19:30:55 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 8.683 s
INFO 11-30 19:31:11 [monitor.py:33] torch.compile takes 30.10 s in total
INFO 11-30 19:31:12 [kv_cache_utils.py:634] GPU KV cache size: 447,088 tokens
INFO 11-30 19:31:12 [kv_cache_utils.py:637] Maximum concurrency for 20,000 tokens per request: 22.35x
